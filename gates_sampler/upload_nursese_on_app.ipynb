{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Title: Nurse connect Gates Investigation\n",
    "# Doc # : Gates-1000-001 Upload Table of NC mobile users\n",
    "# Author: Charles Copley\n",
    "# Date : 27 June 2017\n",
    "# Revision: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import numpy as np\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import GeoJSONDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.sample_geojson import geojson\n",
    "import psycopg2\n",
    "import json\n",
    "from bokeh.events import ButtonClick\n",
    "from bokeh.models import Button\n",
    "from random import random\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import Button\n",
    "from bokeh.palettes import RdYlBu3\n",
    "from bokeh.plotting import figure, curdoc\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define the class for sampling\n",
    "class SelectSample:\n",
    "    #class to hold all the peripheral things required to sample the main DB\n",
    "    #TBD \n",
    "    #--1. Unit Tests.\n",
    "    #--2. Add capacity for joining new (as yet unseen) tables and information.\n",
    "    #--3. Check the JSON file against the parent table name for column existence.\n",
    "    #--4. Add message set query and message sequence number\n",
    "    \n",
    "    def __init__(self,config_json_file):\n",
    "        #test configuration variables\n",
    "        self.config_json_file = config_json_file\n",
    "        self.read_json_config()\n",
    "        \n",
    "        self.master_db_name = self.data['master_db_name']#this will be added as part of the\n",
    "        self.database_port = self.data['database_port']\n",
    "        self.database_server = self.data['database_server']\n",
    "        self.user = self.data['user']\n",
    "        self.pwd = self.data['pwd']\n",
    "        #configuration script\n",
    "        self.id_column = self.data['id_column'] # column that is used for the unique identifier\n",
    "        self.investigation_id = int(self.data['investigation_id']) # Investigation number tag\n",
    "        self.wave_id = int(self.data['wave_id']) # Investigation number tag\n",
    "        self.parent_table_name = self.data['parent_table_name']\n",
    "        self.filtered_table_name = self.data['filtered_table_name']\n",
    "        self.all_samples_table_name = self.data['all_samples_table_name']\n",
    "        #variable to hold whether the parent table has duplication or not.\n",
    "        self.duplicates = True\n",
    "        \n",
    "        print('master_db_name: ',self.master_db_name)\n",
    "        print('database_port: ',self.database_port)\n",
    "        print('database_server: ',self.database_server)\n",
    "        print('database_user: ',self.user)\n",
    "        print('database_pwd: ',self.pwd)\n",
    "        print('unique_field: ',self.id_column)\n",
    "        print('investigation_id: ',self.investigation_id)\n",
    "        print('all_samples_table: ',self.all_samples_table_name)\n",
    "        print('population_filter: ',self.data['filter'])\n",
    "        print('field_to_split: ', self.data['field_to_randomize'])\n",
    "        print('values_to_use: ', list(self.data['samples_from_field'].keys()))\n",
    "        print('number_to_select: ', list(self.data['samples_from_field'].values()))\n",
    "         #name of the table that keeps all the previous samples\n",
    "        #definition of the filter to be applied to the entire population\n",
    "        filterJsonVals = self.data['filter']\n",
    "        nFilters = len(filterJsonVals)\n",
    "        self.population_filter = filterJsonVals[0]\n",
    "        for i in range(1,nFilters):\n",
    "            print(filterJsonVals[i])\n",
    "            self.population_filter = self.population_filter + \"\"\" and \"\"\" + filterJsonVals[i]\n",
    "            \n",
    "        self.group_filter = self.data['field_to_randomize']\n",
    "        self.group_values = list(self.data['samples_from_field'].keys())\n",
    "        self.group_sample_number = list(self.data['samples_from_field'].values())\n",
    "        #self.group_values = ['afr_ZA','eng_ZA','xho_ZA']\n",
    "        #self.group_sample_number = [1000,200,250]\n",
    "        self.temp_full_sample_table_name = \"temp_wave_%d\"%(int(self.wave_id)) \n",
    "    \n",
    "    def check_duplicates(self):\n",
    "        count_id_column = pd.read_sql(\"\"\"\n",
    "            select count(%s) \n",
    "            from %s \n",
    "            \"\"\"%(self.id_column,self.parent_table_name),self.conn_db)\n",
    "        count_distinct_id_column = pd.read_sql(\"\"\"\n",
    "            select count(distinct(%s)) \n",
    "            from %s \n",
    "            \"\"\"%(self.id_column,self.parent_table_name),self.conn_db)\n",
    "        if(count_id_column['count'].item() !=count_distinct_id_column['count'].item()):\n",
    "            print('ID Column \"%s\" is not unique. \\n Count %d Count distinct %d'%(self.id_column,count_id_column['count'],count_distinct_id_column['count']))\n",
    "            self.duplicates = True\n",
    "        elif(count_id_column['count'].item() == count_distinct_id_column['count'].item()):\n",
    "            print('ID Column \"%s\" is unique. Yay! \\n Count %d Count distinct %d'%(self.id_column,count_id_column['count'],count_distinct_id_column['count']))\n",
    "            self.duplicates = False\n",
    "        return(count_id_column,count_distinct_id_column)\n",
    "    \n",
    "    def read_json_config(self):\n",
    "        with open(self.config_json_file) as data_file:\n",
    "            self.data = json.load(data_file)\n",
    "        return(self.data)\n",
    "   \n",
    "    def connect_to_db(self):\n",
    "        self.conn_db=psycopg2.connect(dbname=self.master_db_name,user=self.user,password=self.pwd,\n",
    "                port=self.database_port, host=self.database_server)\n",
    "    \n",
    "    def disconnect_from_db(self):\n",
    "        self.conn_db.close()\n",
    "\n",
    "    def read_test_data(self,file_to_read):\n",
    "        test_data = pd.read_csv(file_to_read)\n",
    "        return test_data\n",
    "    \n",
    "    def create_facility_augmented_database(self):\n",
    "        self.parent_table_facility_code = \"facility_code\"\n",
    "        self.clinic_table_facility_code = \"facilitycode\"\n",
    "        self.clinic_facility_table = \"clinic_facilities_with_gps\"\n",
    "        self.temp_augmented_table = \"temp_table_for_augmented_facilities\"\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands over psycopg2\n",
    "\n",
    "        sql_execution = \"\"\"\n",
    "                    CREATE TEMP TABLE %s as\n",
    "                    (select * from %s as a\n",
    "                    left join %s as b\n",
    "                    on a.%s::integer = b.%s::integer);\n",
    "                    \"\"\"%(self.temp_augmented_table,self.parent_table_name,self.data[\"clinic_facility_table\"], \n",
    "                        self.data[\"parent_table_facility_code\"], self.data[\"clinic_table_facility_code\"])\n",
    "        conn.execute(sql_execution)\n",
    "        conn.close()\n",
    "    \n",
    "    def create_filtered_database(self):\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands over psycopg2\n",
    "        sql_execution = \"\"\"DROP TABLE IF EXISTS %s;\"\"\"%(self.filtered_table_name)\n",
    "        conn.execute(sql_execution)\n",
    "        sql_execution = \"\"\"\n",
    "        CREATE TEMP TABLE %s as (\n",
    "                select *,\n",
    "                %s as investigation_id, \n",
    "                %s as wave_id,\n",
    "                '%s' as sample_config,\n",
    "                '%s' as master_db_name,\n",
    "                '%s' as parent_table_name\n",
    "                from %s \n",
    "                where %s \n",
    "                );\n",
    "        \"\"\"%(self.filtered_table_name,\n",
    "             self.investigation_id,\n",
    "             self.wave_id,\n",
    "             self.config_json_file,\n",
    "             self.master_db_name,\n",
    "             self.parent_table_name,\n",
    "             self.parent_table_name,\n",
    "             self.population_filter)\n",
    "        conn.execute(sql_execution)\n",
    "        conn.close()\n",
    "        \n",
    "    def create_full_sample_temp_table(self):\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands\n",
    "        temp_table_name = \"group_0\"\n",
    "        sql_execution = \"\"\"DROP TABLE IF EXISTS %s;\"\"\"%(self.temp_full_sample_table_name)\n",
    "        conn.execute(sql_execution)\n",
    "        sql_execution = \"\"\"CREATE TEMP TABLE  %s (LIKE %s);\"\"\"%(self.temp_full_sample_table_name,temp_table_name)\n",
    "        conn.execute(sql_execution)\n",
    "        conn.close()\n",
    "    \n",
    "    #check if the table is required for the gates samples   \n",
    "    def check_exists_investigations_gates_table(self):\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands\n",
    "        sql_query = \"\"\"SELECT EXISTS \n",
    "        (SELECT 1 FROM   pg_tables \n",
    "            WHERE  schemaname = 'public' AND tablename = '%s');\"\"\"%(self.all_samples_table_name)\n",
    "        conn.execute(sql_query)\n",
    "        self.exists = conn.fetchall()[0][0]\n",
    "        conn.close()\n",
    "        return self.exists\n",
    "\n",
    "    def create_all_investigations_gates_table_if_not_exist(self):\n",
    "        \"\"\"create the table to hold all the gates investigations if required\"\"\"  \n",
    "        #create cursor to execute the direct db commands\n",
    "        if (not self.check_exists_investigations_gates_table()):\n",
    "            conn = self.conn_db.cursor()\n",
    "            sql_execution = \"\"\"CREATE TABLE %s as (select * from %s where 1=2) ;\"\"\"%(self.all_samples_table_name, self.temp_full_sample_table_name)\n",
    "            conn.execute(sql_execution)\n",
    "            self.conn_db.commit()\n",
    "            conn.close()\n",
    "\n",
    "    def append_group_sample(self,group_id):\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands\n",
    "        temp_full_sample_table_name = \"temp_wave_%d\"%(self.wave_id)\n",
    "        temp_table_name = \"group_\"+str(group_id)\n",
    "        sql_execution = \"\"\"insert into %s select * from %s;\"\"\"%(self.temp_full_sample_table_name,temp_table_name)\n",
    "        result = conn.execute(sql_execution)\n",
    "        self.conn_db.commit()\n",
    "        conn.close()\n",
    "        return(result)\n",
    "    \n",
    "    def append_sample_to_all_investigation(self):\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands\n",
    "        sql_execution = \"\"\"insert into %s select * from %s;\"\"\"%(self.all_samples_table_name,self.temp_full_sample_table_name)\n",
    "        result = conn.execute(sql_execution)\n",
    "        self.conn_db.commit()\n",
    "        conn.close()\n",
    "        return(result)\n",
    "    \n",
    "    def sample_groups(self):\n",
    "        for group_id in range(0,len(self.group_values)):\n",
    "            (a,b,df) = self.get_group_sample(group_id,\n",
    "                                             self.investigation_id,\n",
    "                                             self.wave_id,\n",
    "                                             self.filtered_table_name,\n",
    "                                             self.population_filter,\n",
    "                                             self.group_filter,\n",
    "                                             self.group_values[group_id],\n",
    "                                             int(self.group_sample_number[group_id]))\n",
    "            print('group_id: ',group_id,self.group_values[group_id])\n",
    "        return(a,b,df)\n",
    "    \n",
    "    def append_groups(self):\n",
    "        for i in range(0,len(self.group_values)):\n",
    "            self.append_group_sample(i)\n",
    "    \n",
    "    def get_group_sample(self,group_id,investigation_id, wave_id,parent_table_name,\n",
    "                         population_filter,group_filter,group_value,samples):\n",
    "        #function to get the random samples from a given group\n",
    "        conn = self.conn_db.cursor() #create cursor to execute the direct db commands over psycopg2\n",
    "        temp_table_name = \"group_\"+str(group_id)\n",
    "        sql_execution = \"\"\"DROP TABLE IF EXISTS %s;\"\"\"%(temp_table_name)\n",
    "        conn.execute(sql_execution)\n",
    "        sql_execution = \"\"\"\n",
    "        CREATE TEMP TABLE %s as (\n",
    "                select *,\n",
    "                    random() as random,\n",
    "                    %d as group_id\n",
    "                from %s \n",
    "                where %s \n",
    "                and %s in ('%s') \n",
    "                order by random asc \n",
    "                limit %d);\n",
    "        \"\"\"%(temp_table_name,group_id,\n",
    "             parent_table_name,population_filter,\n",
    "             group_filter,group_value,\n",
    "             samples)\n",
    "        conn.execute(sql_execution)\n",
    "        sql_execution_count = \"\"\"\n",
    "                select count(*)\n",
    "                from %s\n",
    "                where %s \n",
    "                and %s in ('%s');\n",
    "                \"\"\"%(parent_table_name,population_filter,group_filter,group_value)\n",
    "        count = conn.execute(sql_execution_count)\n",
    "        sample_count = pd.read_sql(\"\"\"\n",
    "                select count(*) \n",
    "                from %s;\n",
    "                \"\"\"%(temp_table_name),self.conn_db)\n",
    "        full_count = pd.read_sql(\"\"\"\n",
    "                select count(*) \n",
    "                from %s \n",
    "                where %s \n",
    "                and %s in ('%s')\n",
    "                \"\"\"%(parent_table_name,population_filter,group_filter,group_value),self.conn_db)\n",
    "        sample = pd.read_sql(\"\"\"\n",
    "                select * from %s;\n",
    "                \"\"\"%(temp_table_name),self.conn_db)\n",
    "        conn.close()\n",
    "        if sample_count['count'][0] < samples:\n",
    "            # Create a new instance of an exception\n",
    "            print('error')\n",
    "            sample_error = ValueError(\"The requested sample from %s is too large\" % (group_value))\n",
    "            raise sample_error\n",
    "        return(sample_count, full_count, sample)\n",
    "\n",
    "    def get_final_wave_sample(self):\n",
    "        \"\"\"Return the samples that will be added for the final wave\"\"\"\n",
    "        full_sample = pd.read_sql(\"\"\"\n",
    "            select * \n",
    "            from %s \n",
    "            \"\"\"%(self.temp_full_sample_table_name),self.conn_db)\n",
    "        return full_sample\n",
    "    \n",
    "    def get_augmented_sample(self):\n",
    "        \"\"\"Return the samples that have had clinic locations augmented using the facility code\"\"\"\n",
    "        full_sample = pd.read_sql(\"\"\"\n",
    "            select * \n",
    "            from temp_table_for_augmented_facilities\n",
    "            \"\"\",self.conn_db)\n",
    "        return full_sample\n",
    "    \n",
    "    def get_all_investigations_sample(self):\n",
    "        \"\"\"Return the samples already stored in the Gates investigation table\"\"\"\n",
    "        all_investigations_sample = pd.read_sql(\"\"\"\n",
    "            select * \n",
    "            from %s \n",
    "            \"\"\"%(self.all_samples_table_name),self.conn_db)\n",
    "        return all_investigations_sample\n",
    "    \n",
    "    \n",
    "    def json_config_fields(self):\n",
    "        \"\"\"Return the configuration fields used in the JSON configuration file\"\"\"\n",
    "        return(self.group_filter,self.group_values)\n",
    "    \n",
    "    def plot_histogram(self):\n",
    "        self.get_final_wave_sample().groupby(self.data['field_to_randomize']).count()[self.data['id_column']].plot('bar')\n",
    "    \n",
    "    def return_pandas_sql_query(self,sql):\n",
    "        #function to return a pandas dataframe of the temporary tables created above:\n",
    "        #Typically these will be:\n",
    "        #1. parent_table_name\n",
    "        #2. gates_investigation_%d_filtered\n",
    "        #3. all_gates_investigation_samples\n",
    "        #4. temp_wave_%d\n",
    "        #5. group_%d\n",
    "        return(pd.read_sql(sql,self.conn_db))\n",
    "    \n",
    "    def clinic_locations_of_participants(self):\n",
    "#        sql_execution = \"\"\"\n",
    "#                select a.*,b.lat,b.lon from\n",
    "#                temp_wave_1 as a\n",
    "#                join\n",
    "#                clinic_facilities_with_gps as b\n",
    "#                on a.%s::integer = b.%s::integer\n",
    "#                ;\n",
    "#        \"\"\"%(self.parent_table_facility_code,self.clinic_table_facility_code)\n",
    "        sql_execution = \"\"\"\n",
    "                select * from\n",
    "                temp_wave_1\n",
    "                ;\n",
    "        \"\"\"\n",
    "        return(pd.read_sql(sql_execution,self.conn_db))\n",
    "    \n",
    "    def generate_folium_map(self):\n",
    "        import folium\n",
    "        locations = self.clinic_locations_of_participants().dropna(subset=['lon','lat'])  \n",
    "        m = folium.Map(location=[-30.92, 24.42],zoom_start=5,width=800, height=480)  \n",
    "        marker_cluster = folium.MarkerCluster().add_to(m)\n",
    "        for each in zip(locations.lat, locations.lon):\n",
    "            folium.Marker(each).add_to(marker_cluster)\n",
    "        m.save('base_map.html')\n",
    "        return(m)\n",
    "    \n",
    "    def return_conn_db(self):\n",
    "        return self.conn_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mobi_users = pd.read_csv('NurseConnect_mobi_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobi_users.columns = ['mobi_msisdn','facility_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobi_msisdn</th>\n",
       "      <th>facility_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27849862597</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27849572147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27849278227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27849221829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27848882750</td>\n",
       "      <td>236733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27848727769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27848205119</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27847257566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27847224516</td>\n",
       "      <td>474051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27847017995</td>\n",
       "      <td>147360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27846622155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27846284995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27846043458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27845033594</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27844715231</td>\n",
       "      <td>123456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27844646342</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27844194670</td>\n",
       "      <td>877542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27844061917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27844007639</td>\n",
       "      <td>123456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27843937809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27842687599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27842385378</td>\n",
       "      <td>821415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27842301821</td>\n",
       "      <td>431111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27840667990</td>\n",
       "      <td>258251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27840624642</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27840487425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27840458398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27839860066</td>\n",
       "      <td>110124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27839843520</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27839733264</td>\n",
       "      <td>546324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>27616745052</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>27614232999</td>\n",
       "      <td>784806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>27613219358</td>\n",
       "      <td>430660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>27612682688</td>\n",
       "      <td>667460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>27611146609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>27609959838</td>\n",
       "      <td>333920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>27609628326</td>\n",
       "      <td>839742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>27608763583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>27608745697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>27608216727</td>\n",
       "      <td>436251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>27607572721</td>\n",
       "      <td>828133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>27606838416</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>27606689726</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>27606480991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>27606304844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>27605051225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>27604876868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>27604856395</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>27604775938</td>\n",
       "      <td>496751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>27604338167</td>\n",
       "      <td>212260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27604225295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>27604177599</td>\n",
       "      <td>613124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>27604175397</td>\n",
       "      <td>678451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>27604062938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>27603751044</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>27603613540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>27603595515</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>27603460680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>27603383397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27123456789</td>\n",
       "      <td>880051.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mobi_msisdn  facility_code\n",
       "0    27849862597            NaN\n",
       "1    27849572147            NaN\n",
       "2    27849278227            NaN\n",
       "3    27849221829            NaN\n",
       "4    27848882750       236733.0\n",
       "5    27848727769            NaN\n",
       "6    27848205119            NaN\n",
       "7    27847257566            NaN\n",
       "8    27847224516       474051.0\n",
       "9    27847017995       147360.0\n",
       "10   27846622155            NaN\n",
       "11   27846284995            NaN\n",
       "12   27846043458            NaN\n",
       "13   27845033594            NaN\n",
       "14   27844715231       123456.0\n",
       "15   27844646342            NaN\n",
       "16   27844194670       877542.0\n",
       "17   27844061917            NaN\n",
       "18   27844007639       123456.0\n",
       "19   27843937809            NaN\n",
       "20   27842687599            NaN\n",
       "21   27842385378       821415.0\n",
       "22   27842301821       431111.0\n",
       "23   27840667990       258251.0\n",
       "24   27840624642            NaN\n",
       "25   27840487425            NaN\n",
       "26   27840458398            NaN\n",
       "27   27839860066       110124.0\n",
       "28   27839843520            NaN\n",
       "29   27839733264       546324.0\n",
       "..           ...            ...\n",
       "866  27616745052            NaN\n",
       "867  27614232999       784806.0\n",
       "868  27613219358       430660.0\n",
       "869  27612682688       667460.0\n",
       "870  27611146609            NaN\n",
       "871  27609959838       333920.0\n",
       "872  27609628326       839742.0\n",
       "873  27608763583            NaN\n",
       "874  27608745697            NaN\n",
       "875  27608216727       436251.0\n",
       "876  27607572721       828133.0\n",
       "877  27606838416            NaN\n",
       "878  27606689726            NaN\n",
       "879  27606480991            NaN\n",
       "880  27606304844            NaN\n",
       "881  27605051225            NaN\n",
       "882  27604876868            NaN\n",
       "883  27604856395            NaN\n",
       "884  27604775938       496751.0\n",
       "885  27604338167       212260.0\n",
       "886  27604225295            NaN\n",
       "887  27604177599       613124.0\n",
       "888  27604175397       678451.0\n",
       "889  27604062938            NaN\n",
       "890  27603751044            NaN\n",
       "891  27603613540            NaN\n",
       "892  27603595515            NaN\n",
       "893  27603460680            NaN\n",
       "894  27603383397            NaN\n",
       "895  27123456789       880051.0\n",
       "\n",
       "[896 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobi_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://charlescopley:parham@localhost:6432/charlescopley')\n",
    "mobi_users.to_sql('nurse_connect_mobi_users', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
